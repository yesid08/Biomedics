{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bienvenidos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estos notebooks vamos a correr una red neuronal para interpretar texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "from matplotlib import pylab\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mattmahoney.net/dc/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if not os.path.exists(filename):\n",
    "    filename, _ = urlretrieve(url + filename, filename)\n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified %s' % filename)\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "filename = maybe_download('text8.zip', 31344016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 17005207\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "  \"\"\"Extract the first file enclosed in a zip file as a list of words\"\"\"\n",
    "  with zipfile.ZipFile(filename) as f:\n",
    "    data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "  return data\n",
    "  \n",
    "words = read_data(filename)\n",
    "print('Data size %d' % len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\n",
      "Sample data [5234, 3081, 12, 6, 195, 2, 3134, 46, 59, 156]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 50000\n",
    "\n",
    "def build_dataset(words):\n",
    "  count = [['UNK', -1]]\n",
    "  count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "  dictionary = dict()\n",
    "  for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "  data = list()\n",
    "  unk_count = 0\n",
    "  for word in words:\n",
    "    if word in dictionary:\n",
    "      index = dictionary[word]\n",
    "    else:\n",
    "      index = 0  # dictionary['UNK']\n",
    "      unk_count = unk_count + 1\n",
    "    data.append(index)\n",
    "  count[0][1] = unk_count\n",
    "  reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "  return data, count, dictionary, reverse_dictionary\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(words)\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10])\n",
    "del words  # Hint to reduce memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "\n",
    "# skip_window: int : How many words to consider left and right.\n",
    "def generate_cbow_batch(batch_size, skip_window):\n",
    "  global data_index\n",
    "#   assert batch_size % num_skips == 0\n",
    "#   assert num_skips <= 2 * skip_window\n",
    "  batch = np.ndarray(shape=(batch_size, skip_window*2), dtype=np.int32)\n",
    "  labels = np.ndarray(shape=(batch_size,1), dtype=np.int32)\n",
    "  span = 2 * skip_window + 1 # [ skip_window target skip_window ]\n",
    "  buffer = collections.deque(maxlen=span)\n",
    "#   buffer = []\n",
    "  for _ in range(span):\n",
    "    buffer.append(data[data_index])\n",
    "    data_index = (data_index + 1) % len(data)\n",
    "    print(\"data_index:{} buffer {}\".format(data_index,buffer[data_index-1]))\n",
    "  \n",
    "  for i in range(batch_size):\n",
    "    batch[i] = list(buffer)[:skip_window] + list(buffer)[skip_window+1:]\n",
    "    labels[i] = buffer[skip_window]\n",
    "    buffer.append(data[data_index])\n",
    "    data_index = (data_index + 1) % len(data)\n",
    "    \n",
    "  return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_index:1 buffer 5234\n",
      "data_index:2 buffer 3081\n",
      "data_index:3 buffer 12\n"
     ]
    }
   ],
   "source": [
    "batch,labels = generate_cbow_batch(128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5234,   12],\n",
       "       [3081,    6],\n",
       "       [  12,  195],\n",
       "       [   6,    2],\n",
       "       [ 195, 3134],\n",
       "       [   2,   46],\n",
       "       [3134,   59],\n",
       "       [  46,  156],\n",
       "       [  59,  128],\n",
       "       [ 156,  742]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3081],\n",
       "       [  12],\n",
       "       [   6],\n",
       "       [ 195],\n",
       "       [   2],\n",
       "       [3134],\n",
       "       [  46],\n",
       "       [  59],\n",
       "       [ 156],\n",
       "       [ 128]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (of,first) -- label:(abuse)\n",
      "input: (abuse,used) -- label:(first)\n",
      "input: (first,against) -- label:(used)\n",
      "input: (used,early) -- label:(against)\n",
      "input: (against,working) -- label:(early)\n",
      "input: (early,class) -- label:(working)\n",
      "input: (working,radicals) -- label:(class)\n",
      "input: (class,including) -- label:(radicals)\n",
      "input: (radicals,the) -- label:(including)\n",
      "input: (including,diggers) -- label:(the)\n",
      "input: (the,of) -- label:(diggers)\n",
      "input: (diggers,the) -- label:(of)\n",
      "input: (of,english) -- label:(the)\n",
      "input: (the,revolution) -- label:(english)\n",
      "input: (english,and) -- label:(revolution)\n",
      "input: (revolution,the) -- label:(and)\n",
      "input: (and,sans) -- label:(the)\n",
      "input: (the,UNK) -- label:(sans)\n",
      "input: (sans,of) -- label:(UNK)\n",
      "input: (UNK,the) -- label:(of)\n",
      "input: (of,french) -- label:(the)\n",
      "input: (the,revolution) -- label:(french)\n",
      "input: (french,whilst) -- label:(revolution)\n",
      "input: (revolution,the) -- label:(whilst)\n",
      "input: (whilst,term) -- label:(the)\n",
      "input: (the,is) -- label:(term)\n",
      "input: (term,still) -- label:(is)\n",
      "input: (is,used) -- label:(still)\n",
      "input: (still,in) -- label:(used)\n",
      "input: (used,a) -- label:(in)\n",
      "input: (in,pejorative) -- label:(a)\n",
      "input: (a,way) -- label:(pejorative)\n",
      "input: (pejorative,to) -- label:(way)\n",
      "input: (way,describe) -- label:(to)\n",
      "input: (to,any) -- label:(describe)\n",
      "input: (describe,act) -- label:(any)\n",
      "input: (any,that) -- label:(act)\n",
      "input: (act,used) -- label:(that)\n",
      "input: (that,violent) -- label:(used)\n",
      "input: (used,means) -- label:(violent)\n",
      "input: (violent,to) -- label:(means)\n",
      "input: (means,destroy) -- label:(to)\n",
      "input: (to,the) -- label:(destroy)\n",
      "input: (destroy,organization) -- label:(the)\n",
      "input: (the,of) -- label:(organization)\n",
      "input: (organization,society) -- label:(of)\n",
      "input: (of,it) -- label:(society)\n",
      "input: (society,has) -- label:(it)\n",
      "input: (it,also) -- label:(has)\n",
      "input: (has,been) -- label:(also)\n",
      "input: (also,taken) -- label:(been)\n",
      "input: (been,up) -- label:(taken)\n",
      "input: (taken,as) -- label:(up)\n",
      "input: (up,a) -- label:(as)\n",
      "input: (as,positive) -- label:(a)\n",
      "input: (a,label) -- label:(positive)\n",
      "input: (positive,by) -- label:(label)\n",
      "input: (label,self) -- label:(by)\n",
      "input: (by,defined) -- label:(self)\n",
      "input: (self,anarchists) -- label:(defined)\n",
      "input: (defined,the) -- label:(anarchists)\n",
      "input: (anarchists,word) -- label:(the)\n",
      "input: (the,anarchism) -- label:(word)\n",
      "input: (word,is) -- label:(anarchism)\n",
      "input: (anarchism,derived) -- label:(is)\n",
      "input: (is,from) -- label:(derived)\n",
      "input: (derived,the) -- label:(from)\n",
      "input: (from,greek) -- label:(the)\n",
      "input: (the,without) -- label:(greek)\n",
      "input: (greek,archons) -- label:(without)\n",
      "input: (without,ruler) -- label:(archons)\n",
      "input: (archons,chief) -- label:(ruler)\n",
      "input: (ruler,king) -- label:(chief)\n",
      "input: (chief,anarchism) -- label:(king)\n",
      "input: (king,as) -- label:(anarchism)\n",
      "input: (anarchism,a) -- label:(as)\n",
      "input: (as,political) -- label:(a)\n",
      "input: (a,philosophy) -- label:(political)\n",
      "input: (political,is) -- label:(philosophy)\n",
      "input: (philosophy,the) -- label:(is)\n",
      "input: (is,belief) -- label:(the)\n",
      "input: (the,that) -- label:(belief)\n",
      "input: (belief,rulers) -- label:(that)\n",
      "input: (that,are) -- label:(rulers)\n",
      "input: (rulers,unnecessary) -- label:(are)\n",
      "input: (are,and) -- label:(unnecessary)\n",
      "input: (unnecessary,should) -- label:(and)\n",
      "input: (and,be) -- label:(should)\n",
      "input: (should,abolished) -- label:(be)\n",
      "input: (be,although) -- label:(abolished)\n",
      "input: (abolished,there) -- label:(although)\n",
      "input: (although,are) -- label:(there)\n",
      "input: (there,differing) -- label:(are)\n",
      "input: (are,interpretations) -- label:(differing)\n",
      "input: (differing,of) -- label:(interpretations)\n",
      "input: (interpretations,what) -- label:(of)\n",
      "input: (of,this) -- label:(what)\n",
      "input: (what,means) -- label:(this)\n",
      "input: (this,anarchism) -- label:(means)\n",
      "input: (means,also) -- label:(anarchism)\n",
      "input: (anarchism,refers) -- label:(also)\n",
      "input: (also,to) -- label:(refers)\n",
      "input: (refers,related) -- label:(to)\n",
      "input: (to,social) -- label:(related)\n",
      "input: (related,movements) -- label:(social)\n",
      "input: (social,that) -- label:(movements)\n",
      "input: (movements,advocate) -- label:(that)\n",
      "input: (that,the) -- label:(advocate)\n",
      "input: (advocate,elimination) -- label:(the)\n",
      "input: (the,of) -- label:(elimination)\n",
      "input: (elimination,authoritarian) -- label:(of)\n",
      "input: (of,institutions) -- label:(authoritarian)\n",
      "input: (authoritarian,particularly) -- label:(institutions)\n",
      "input: (institutions,the) -- label:(particularly)\n",
      "input: (particularly,state) -- label:(the)\n",
      "input: (the,the) -- label:(state)\n",
      "input: (state,word) -- label:(the)\n",
      "input: (the,anarchy) -- label:(word)\n",
      "input: (word,as) -- label:(anarchy)\n",
      "input: (anarchy,most) -- label:(as)\n"
     ]
    }
   ],
   "source": [
    "for i in range (np.random.randint(28) , np.random.randint(28)+100 ):\n",
    "    print ('input: ({},{}) -- label:({})'.format(reverse_dictionary[batch[i,0]], reverse_dictionary[batch[i,1]],\n",
    "                                                reverse_dictionary[labels[i][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
