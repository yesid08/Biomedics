{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORPUS PARA ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "\n",
    "def get_corpus_from_csv(filename,delimeter):\n",
    "    coments = pd.read_csv(filename,sep=delimeter)\n",
    "    corpus = []\n",
    "    for i in range(len(coments)):\n",
    "        oraciones = []\n",
    "        sentence = coments.orth.iloc[i]\n",
    "        sentence = sentence.split(' ')\n",
    "        for word in sentence:\n",
    "            if word != \"[SILENCE]\":\n",
    "                word = word.replace('.','')\n",
    "                word = word.replace(',','')\n",
    "                word = word.replace('?','')\n",
    "            \n",
    "                word = word.lower()\n",
    "                oraciones.append(word)\n",
    "        corpus.append(oraciones)\n",
    "    return corpus\n",
    "filename = \"train.sentences.pronunciations.multi.translations.csv\"\n",
    "delimiter = ';'\n",
    "\n",
    "def get_corpus_distinct_from_corpus(corpus):\n",
    "    corpus_distint = []\n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            if word not in corpus_distint:\n",
    "                corpus_distint.append(word)\n",
    "    return corpus_distint\n",
    "\n",
    "corpus = get_corpus_from_csv(filename,delimiter)\n",
    "corpus_distinct = get_corpus_distinct_from_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"corpus.txt\",\"w\")  \n",
    "for sentence in corpus:\n",
    "    for  word  in sentence:\n",
    "        file.write(word+\" \")\n",
    "    file.write(\"\\n\")\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_glove\n",
    "model = tf_glove.GloVeModel(embedding_size=len(corpus_distinct), context_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\juand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\juand\\Documents\\GitHub\\Biomedics\\Juan M\\tf_glove.py:96: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\juand\\Documents\\GitHub\\Biomedics\\Juan M\\tf_glove.py:101: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\juand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model.fit_to_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69354796, -0.3923709 , -0.3853247 ,  0.43878925, -0.02851599,\n",
       "         0.34692553,  0.07892638,  0.30675682, -0.5500167 , -1.7159796 ,\n",
       "         0.76510316,  0.04077822, -0.04356343,  0.7014111 ,  0.07800671,\n",
       "         0.7413534 , -0.9021892 ,  0.7863653 , -0.20411558, -0.86255133,\n",
       "         1.2280962 , -1.1469352 , -0.17653808, -1.2350314 ,  0.8374455 ,\n",
       "        -0.13905925,  0.35496873, -0.14604959, -0.00860152,  0.39901522,\n",
       "         0.4340194 ,  0.17246588, -0.1950115 ,  0.7058366 , -0.5919082 ,\n",
       "         0.5011158 , -1.1745951 , -0.5128975 , -0.23313515,  0.08170503,\n",
       "        -0.14134687,  1.3697032 , -1.3980184 , -0.25380903, -0.09738231,\n",
       "         0.8913454 ,  0.50387895,  0.12423915, -0.50868213, -0.72772807,\n",
       "        -1.2128891 , -0.19833255,  0.61300844, -0.32998884,  0.8190512 ,\n",
       "        -0.4389441 , -1.2499316 ,  0.20564741, -0.11851406,  0.574084  ,\n",
       "         0.27699828,  0.22930425, -0.9359445 , -0.15061548,  0.6110869 ,\n",
       "        -0.18205136,  0.12553231,  0.15472114,  1.1101687 , -0.21637756,\n",
       "        -0.09965298, -0.21135767,  0.66068065, -0.3992872 , -1.3373563 ,\n",
       "        -0.7993278 ,  0.01617229,  0.47004008,  0.24568899,  1.0824174 ,\n",
       "        -0.7822539 ,  1.2919021 ,  0.94028175,  0.3176785 ,  0.16436696,\n",
       "        -0.98178196, -0.77373576,  0.5539515 ,  0.12595698, -1.6346194 ,\n",
       "         0.19484088, -0.03988647,  0.9943936 , -0.4212851 , -1.2051748 ,\n",
       "        -0.03884777,  0.06936158, -1.2693665 , -0.6721226 ,  1.068203  ,\n",
       "        -0.12547201,  1.1096447 ,  0.10372375, -0.49408066,  0.05227894,\n",
       "        -1.5333415 , -1.4572752 ,  1.0786439 ,  0.6678987 ,  1.5405374 ,\n",
       "        -1.63836   , -0.8825206 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding_for(\"john\").reshape(1,len(corpus_distinct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTACIÃ“N KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump,load\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abriendo archivo de traslation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus lenght in characters: 3970\n"
     ]
    }
   ],
   "source": [
    "link=\"corpus.txt\"\n",
    "with io.open(link,encoding='utf-8') as f:\n",
    "  data=f.read().lower() #.replace('\\n',' \\n ')\n",
    "print('Corpus lenght in characters:',len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando un token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words:  116\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer()\n",
    "corpus=data.lower().split(\"\\n\")    \n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words=len(tokenizer.word_index) + 1\n",
    "print('Total words: ',total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar Secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 574\n"
     ]
    }
   ],
   "source": [
    "input_sequences=[]\n",
    "for line in corpus:\n",
    "  token_list=tokenizer.texts_to_sequences([line])[0]\n",
    "  for i in range(1,len(token_list)):\n",
    "    n_gram_sequence=token_list[:i+1]\n",
    "    input_sequences.append(n_gram_sequence)\n",
    "print('Total Sequences:',len(input_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 8\n"
     ]
    }
   ],
   "source": [
    "max_sequence_len=max([len(x) for x in input_sequences])\n",
    "input_sequences=np.array(pad_sequences(input_sequences,maxlen=max_sequence_len,padding='pre'))\n",
    "print('Max Sequence Length:',max_sequence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividiendo las secuencias en etiquetas X(entradas - inputs) y y (salidas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=np.array(input_sequences)\n",
    "X,y=sequences[:,:-1],sequences[:,-1]\n",
    "y=to_categorical(y,num_classes=total_words,dtype='int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir el modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 7, 10)             1160      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 116)               5916      \n",
      "=================================================================\n",
      "Total params: 19,276\n",
      "Trainable params: 19,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(total_words,10,input_length=max_sequence_len-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(total_words,activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "574/574 [==============================] - 2s 4ms/step - loss: 4.7440 - acc: 0.0453\n",
      "Epoch 2/350\n",
      "574/574 [==============================] - 0s 292us/step - loss: 4.6907 - acc: 0.0767\n",
      "Epoch 3/350\n",
      "574/574 [==============================] - 0s 271us/step - loss: 4.4388 - acc: 0.0819\n",
      "Epoch 4/350\n",
      "574/574 [==============================] - 0s 275us/step - loss: 4.2292 - acc: 0.0819\n",
      "Epoch 5/350\n",
      "574/574 [==============================] - 0s 286us/step - loss: 4.1945 - acc: 0.0819\n",
      "Epoch 6/350\n",
      "574/574 [==============================] - 0s 281us/step - loss: 4.1779 - acc: 0.0819\n",
      "Epoch 7/350\n",
      "574/574 [==============================] - 0s 275us/step - loss: 4.1677 - acc: 0.0819\n",
      "Epoch 8/350\n",
      "574/574 [==============================] - 0s 282us/step - loss: 4.1568 - acc: 0.0819\n",
      "Epoch 9/350\n",
      "574/574 [==============================] - 0s 272us/step - loss: 4.1451 - acc: 0.0819\n",
      "Epoch 10/350\n",
      "574/574 [==============================] - 0s 282us/step - loss: 4.1319 - acc: 0.0819\n",
      "Epoch 11/350\n",
      "574/574 [==============================] - 0s 277us/step - loss: 4.1168 - acc: 0.0819\n",
      "Epoch 12/350\n",
      "574/574 [==============================] - 0s 293us/step - loss: 4.0986 - acc: 0.0819\n",
      "Epoch 13/350\n",
      "574/574 [==============================] - 0s 286us/step - loss: 4.0823 - acc: 0.0819\n",
      "Epoch 14/350\n",
      "574/574 [==============================] - 0s 279us/step - loss: 4.0622 - acc: 0.0819\n",
      "Epoch 15/350\n",
      "574/574 [==============================] - 0s 306us/step - loss: 4.0430 - acc: 0.0819\n",
      "Epoch 16/350\n",
      "574/574 [==============================] - 0s 340us/step - loss: 4.0120 - acc: 0.0819\n",
      "Epoch 17/350\n",
      "574/574 [==============================] - 0s 306us/step - loss: 3.9850 - acc: 0.0889\n",
      "Epoch 18/350\n",
      "574/574 [==============================] - 0s 281us/step - loss: 3.9630 - acc: 0.1167\n",
      "Epoch 19/350\n",
      "574/574 [==============================] - 0s 272us/step - loss: 3.9457 - acc: 0.1202\n",
      "Epoch 20/350\n",
      "574/574 [==============================] - 0s 296us/step - loss: 3.9099 - acc: 0.1167\n",
      "Epoch 21/350\n",
      "574/574 [==============================] - 0s 355us/step - loss: 3.8860 - acc: 0.1185\n",
      "Epoch 22/350\n",
      "574/574 [==============================] - 0s 345us/step - loss: 3.8540 - acc: 0.1185 0s - loss: 3.8756 - acc: 0.12\n",
      "Epoch 23/350\n",
      "574/574 [==============================] - 0s 362us/step - loss: 3.8274 - acc: 0.1080\n",
      "Epoch 24/350\n",
      "574/574 [==============================] - 0s 380us/step - loss: 3.7996 - acc: 0.1132\n",
      "Epoch 25/350\n",
      "574/574 [==============================] - 0s 368us/step - loss: 3.7772 - acc: 0.1063\n",
      "Epoch 26/350\n",
      "574/574 [==============================] - 0s 344us/step - loss: 3.7507 - acc: 0.1185\n",
      "Epoch 27/350\n",
      "574/574 [==============================] - 0s 368us/step - loss: 3.7204 - acc: 0.1150\n",
      "Epoch 28/350\n",
      "574/574 [==============================] - 0s 337us/step - loss: 3.6923 - acc: 0.1185\n",
      "Epoch 29/350\n",
      "574/574 [==============================] - 0s 337us/step - loss: 3.6645 - acc: 0.1289\n",
      "Epoch 30/350\n",
      "574/574 [==============================] - 0s 288us/step - loss: 3.6330 - acc: 0.1376\n",
      "Epoch 31/350\n",
      "574/574 [==============================] - 0s 287us/step - loss: 3.6077 - acc: 0.1376\n",
      "Epoch 32/350\n",
      "574/574 [==============================] - 0s 282us/step - loss: 3.5818 - acc: 0.1463\n",
      "Epoch 33/350\n",
      "574/574 [==============================] - 0s 279us/step - loss: 3.5477 - acc: 0.1411\n",
      "Epoch 34/350\n",
      "574/574 [==============================] - 0s 281us/step - loss: 3.5196 - acc: 0.1498\n",
      "Epoch 35/350\n",
      "574/574 [==============================] - 0s 275us/step - loss: 3.4871 - acc: 0.1585\n",
      "Epoch 36/350\n",
      "574/574 [==============================] - 0s 280us/step - loss: 3.4563 - acc: 0.1568\n",
      "Epoch 37/350\n",
      "574/574 [==============================] - 0s 279us/step - loss: 3.4342 - acc: 0.1568\n",
      "Epoch 38/350\n",
      "574/574 [==============================] - 0s 277us/step - loss: 3.3984 - acc: 0.1603\n",
      "Epoch 39/350\n",
      "574/574 [==============================] - 0s 279us/step - loss: 3.3681 - acc: 0.1568\n",
      "Epoch 40/350\n",
      "574/574 [==============================] - 0s 275us/step - loss: 3.3338 - acc: 0.1707\n",
      "Epoch 41/350\n",
      "574/574 [==============================] - 0s 286us/step - loss: 3.3049 - acc: 0.1707\n",
      "Epoch 42/350\n",
      "574/574 [==============================] - 0s 288us/step - loss: 3.2700 - acc: 0.1794\n",
      "Epoch 43/350\n",
      "574/574 [==============================] - 0s 286us/step - loss: 3.2374 - acc: 0.1847\n",
      "Epoch 44/350\n",
      "574/574 [==============================] - 0s 288us/step - loss: 3.2066 - acc: 0.1864\n",
      "Epoch 45/350\n",
      "574/574 [==============================] - 0s 356us/step - loss: 3.1765 - acc: 0.2125\n",
      "Epoch 46/350\n",
      "574/574 [==============================] - 0s 360us/step - loss: 3.1395 - acc: 0.2143\n",
      "Epoch 47/350\n",
      "574/574 [==============================] - 0s 456us/step - loss: 3.1085 - acc: 0.2213\n",
      "Epoch 48/350\n",
      "574/574 [==============================] - 0s 366us/step - loss: 3.0818 - acc: 0.2143\n",
      "Epoch 49/350\n",
      "574/574 [==============================] - 0s 401us/step - loss: 3.0492 - acc: 0.2282\n",
      "Epoch 50/350\n",
      "574/574 [==============================] - 0s 440us/step - loss: 3.0268 - acc: 0.2456\n",
      "Epoch 51/350\n",
      "574/574 [==============================] - 0s 422us/step - loss: 2.9889 - acc: 0.2474\n",
      "Epoch 52/350\n",
      "574/574 [==============================] - 0s 432us/step - loss: 2.9600 - acc: 0.2544\n",
      "Epoch 53/350\n",
      "574/574 [==============================] - 0s 499us/step - loss: 2.9354 - acc: 0.2491\n",
      "Epoch 54/350\n",
      "574/574 [==============================] - 0s 461us/step - loss: 2.8983 - acc: 0.2753\n",
      "Epoch 55/350\n",
      "574/574 [==============================] - 0s 434us/step - loss: 2.8834 - acc: 0.2840\n",
      "Epoch 56/350\n",
      "574/574 [==============================] - 0s 400us/step - loss: 2.8459 - acc: 0.2875\n",
      "Epoch 57/350\n",
      "574/574 [==============================] - 0s 406us/step - loss: 2.8114 - acc: 0.2909\n",
      "Epoch 58/350\n",
      "574/574 [==============================] - 0s 489us/step - loss: 2.7874 - acc: 0.2857 0s - loss: 2.8468 - acc: 0.\n",
      "Epoch 59/350\n",
      "574/574 [==============================] - 0s 384us/step - loss: 2.7552 - acc: 0.3014\n",
      "Epoch 60/350\n",
      "574/574 [==============================] - 0s 435us/step - loss: 2.7193 - acc: 0.3153\n",
      "Epoch 61/350\n",
      "574/574 [==============================] - 0s 523us/step - loss: 2.6936 - acc: 0.3258\n",
      "Epoch 62/350\n",
      "574/574 [==============================] - 0s 517us/step - loss: 2.6651 - acc: 0.3240\n",
      "Epoch 63/350\n",
      "574/574 [==============================] - 0s 435us/step - loss: 2.6446 - acc: 0.3345\n",
      "Epoch 64/350\n",
      "574/574 [==============================] - 0s 392us/step - loss: 2.6176 - acc: 0.3432\n",
      "Epoch 65/350\n",
      "574/574 [==============================] - 0s 528us/step - loss: 2.5917 - acc: 0.3415\n",
      "Epoch 66/350\n",
      "574/574 [==============================] - 0s 494us/step - loss: 2.5640 - acc: 0.3571\n",
      "Epoch 67/350\n",
      "574/574 [==============================] - 0s 698us/step - loss: 2.5348 - acc: 0.3537 0s - loss: 2.5409 - acc: 0.3\n",
      "Epoch 68/350\n",
      "574/574 [==============================] - 0s 520us/step - loss: 2.5068 - acc: 0.3676 0s - loss: 2.6498 - acc: 0.\n",
      "Epoch 69/350\n",
      "574/574 [==============================] - 0s 513us/step - loss: 2.4885 - acc: 0.3624\n",
      "Epoch 70/350\n",
      "574/574 [==============================] - 0s 494us/step - loss: 2.4606 - acc: 0.3589\n",
      "Epoch 71/350\n",
      "574/574 [==============================] - 0s 504us/step - loss: 2.4295 - acc: 0.3693\n",
      "Epoch 72/350\n",
      "574/574 [==============================] - 0s 562us/step - loss: 2.4073 - acc: 0.3746 0s - loss: 2.4097 - acc: 0.38\n",
      "Epoch 73/350\n",
      "574/574 [==============================] - 0s 503us/step - loss: 2.3858 - acc: 0.3815\n",
      "Epoch 74/350\n",
      "574/574 [==============================] - 0s 582us/step - loss: 2.3608 - acc: 0.3833\n",
      "Epoch 75/350\n",
      "574/574 [==============================] - 0s 575us/step - loss: 2.3340 - acc: 0.3937\n",
      "Epoch 76/350\n",
      "574/574 [==============================] - 0s 626us/step - loss: 2.3103 - acc: 0.3955\n",
      "Epoch 77/350\n",
      "574/574 [==============================] - 0s 467us/step - loss: 2.2929 - acc: 0.4077 0s - loss: 2.2261 - acc: 0.4\n",
      "Epoch 78/350\n",
      "574/574 [==============================] - 0s 431us/step - loss: 2.2628 - acc: 0.4233\n",
      "Epoch 79/350\n",
      "574/574 [==============================] - 0s 412us/step - loss: 2.2427 - acc: 0.4129\n",
      "Epoch 80/350\n",
      "574/574 [==============================] - 0s 456us/step - loss: 2.2233 - acc: 0.4129\n",
      "Epoch 81/350\n",
      "574/574 [==============================] - 0s 381us/step - loss: 2.1993 - acc: 0.4181\n",
      "Epoch 82/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 0s 372us/step - loss: 2.1758 - acc: 0.4321\n",
      "Epoch 83/350\n",
      "574/574 [==============================] - ETA: 0s - loss: 2.1605 - acc: 0.430 - 0s 457us/step - loss: 2.1565 - acc: 0.4321\n",
      "Epoch 84/350\n",
      "574/574 [==============================] - 0s 444us/step - loss: 2.1313 - acc: 0.4338 0s - loss: 2.1131 - acc: 0.43\n",
      "Epoch 85/350\n",
      "574/574 [==============================] - 0s 481us/step - loss: 2.1087 - acc: 0.4425\n",
      "Epoch 86/350\n",
      "574/574 [==============================] - 0s 541us/step - loss: 2.0949 - acc: 0.4512\n",
      "Epoch 87/350\n",
      "574/574 [==============================] - 0s 745us/step - loss: 2.0746 - acc: 0.4547\n",
      "Epoch 88/350\n",
      "574/574 [==============================] - 1s 939us/step - loss: 2.0572 - acc: 0.4512 0s - loss: 2.0591 - acc: 0.450\n",
      "Epoch 89/350\n",
      "574/574 [==============================] - 0s 595us/step - loss: 2.0382 - acc: 0.4669\n",
      "Epoch 90/350\n",
      "574/574 [==============================] - 0s 406us/step - loss: 2.0163 - acc: 0.4669\n",
      "Epoch 91/350\n",
      "574/574 [==============================] - 0s 493us/step - loss: 2.0006 - acc: 0.4826\n",
      "Epoch 92/350\n",
      "574/574 [==============================] - 0s 434us/step - loss: 1.9761 - acc: 0.4756\n",
      "Epoch 93/350\n",
      "574/574 [==============================] - 0s 614us/step - loss: 1.9669 - acc: 0.4756\n",
      "Epoch 94/350\n",
      "574/574 [==============================] - 0s 502us/step - loss: 1.9479 - acc: 0.4913 0s - loss: 1.8773 - acc: 0.\n",
      "Epoch 95/350\n",
      "574/574 [==============================] - 0s 585us/step - loss: 1.9297 - acc: 0.4878\n",
      "Epoch 96/350\n",
      "574/574 [==============================] - 0s 393us/step - loss: 1.9125 - acc: 0.5070\n",
      "Epoch 97/350\n",
      "574/574 [==============================] - 0s 345us/step - loss: 1.8979 - acc: 0.4983\n",
      "Epoch 98/350\n",
      "574/574 [==============================] - 0s 348us/step - loss: 1.8833 - acc: 0.5192\n",
      "Epoch 99/350\n",
      "574/574 [==============================] - 0s 379us/step - loss: 1.8670 - acc: 0.5070\n",
      "Epoch 100/350\n",
      "574/574 [==============================] - 0s 452us/step - loss: 1.8464 - acc: 0.5139\n",
      "Epoch 101/350\n",
      "574/574 [==============================] - 0s 426us/step - loss: 1.8309 - acc: 0.5261\n",
      "Epoch 102/350\n",
      "574/574 [==============================] - 0s 370us/step - loss: 1.8159 - acc: 0.5296\n",
      "Epoch 103/350\n",
      "574/574 [==============================] - 0s 441us/step - loss: 1.8060 - acc: 0.5174\n",
      "Epoch 104/350\n",
      "574/574 [==============================] - 0s 495us/step - loss: 1.7958 - acc: 0.5279\n",
      "Epoch 105/350\n",
      "574/574 [==============================] - 0s 454us/step - loss: 1.7751 - acc: 0.5453 0s - loss: 1.7733 - acc: 0.54\n",
      "Epoch 106/350\n",
      "574/574 [==============================] - 0s 408us/step - loss: 1.7600 - acc: 0.5366\n",
      "Epoch 107/350\n",
      "574/574 [==============================] - 0s 446us/step - loss: 1.7535 - acc: 0.5505\n",
      "Epoch 108/350\n",
      "574/574 [==============================] - 0s 454us/step - loss: 1.7290 - acc: 0.5523\n",
      "Epoch 109/350\n",
      "574/574 [==============================] - 0s 370us/step - loss: 1.7200 - acc: 0.5645\n",
      "Epoch 110/350\n",
      "574/574 [==============================] - 0s 358us/step - loss: 1.7016 - acc: 0.5627 0s - loss: 1.6793 - acc: 0.566\n",
      "Epoch 111/350\n",
      "574/574 [==============================] - 0s 329us/step - loss: 1.6880 - acc: 0.5645\n",
      "Epoch 112/350\n",
      "574/574 [==============================] - 0s 354us/step - loss: 1.6811 - acc: 0.5819\n",
      "Epoch 113/350\n",
      "574/574 [==============================] - 0s 394us/step - loss: 1.6610 - acc: 0.5784\n",
      "Epoch 114/350\n",
      "574/574 [==============================] - 0s 406us/step - loss: 1.6543 - acc: 0.5732\n",
      "Epoch 115/350\n",
      "574/574 [==============================] - 0s 377us/step - loss: 1.6403 - acc: 0.5749\n",
      "Epoch 116/350\n",
      "574/574 [==============================] - 0s 322us/step - loss: 1.6244 - acc: 0.5889\n",
      "Epoch 117/350\n",
      "574/574 [==============================] - 0s 317us/step - loss: 1.6127 - acc: 0.5854\n",
      "Epoch 118/350\n",
      "574/574 [==============================] - 0s 375us/step - loss: 1.6005 - acc: 0.5941\n",
      "Epoch 119/350\n",
      "574/574 [==============================] - 0s 452us/step - loss: 1.5977 - acc: 0.5976\n",
      "Epoch 120/350\n",
      "574/574 [==============================] - 0s 376us/step - loss: 1.5807 - acc: 0.5976\n",
      "Epoch 121/350\n",
      "574/574 [==============================] - 0s 380us/step - loss: 1.5674 - acc: 0.6028\n",
      "Epoch 122/350\n",
      "574/574 [==============================] - 0s 415us/step - loss: 1.5566 - acc: 0.5993\n",
      "Epoch 123/350\n",
      "574/574 [==============================] - 0s 414us/step - loss: 1.5516 - acc: 0.6080 0s - loss: 1.5547 - acc: 0.612\n",
      "Epoch 124/350\n",
      "574/574 [==============================] - 0s 386us/step - loss: 1.5390 - acc: 0.6115\n",
      "Epoch 125/350\n",
      "574/574 [==============================] - 0s 501us/step - loss: 1.5266 - acc: 0.6080\n",
      "Epoch 126/350\n",
      "574/574 [==============================] - 0s 467us/step - loss: 1.5161 - acc: 0.6098\n",
      "Epoch 127/350\n",
      "574/574 [==============================] - 0s 439us/step - loss: 1.5076 - acc: 0.6098\n",
      "Epoch 128/350\n",
      "574/574 [==============================] - 0s 423us/step - loss: 1.4917 - acc: 0.6132\n",
      "Epoch 129/350\n",
      "574/574 [==============================] - 0s 421us/step - loss: 1.4795 - acc: 0.6098\n",
      "Epoch 130/350\n",
      "574/574 [==============================] - 0s 413us/step - loss: 1.4738 - acc: 0.6150\n",
      "Epoch 131/350\n",
      "574/574 [==============================] - 0s 460us/step - loss: 1.4611 - acc: 0.6185\n",
      "Epoch 132/350\n",
      "574/574 [==============================] - 0s 441us/step - loss: 1.4543 - acc: 0.6237\n",
      "Epoch 133/350\n",
      "574/574 [==============================] - 0s 535us/step - loss: 1.4470 - acc: 0.6376\n",
      "Epoch 134/350\n",
      "574/574 [==============================] - 0s 418us/step - loss: 1.4345 - acc: 0.6237\n",
      "Epoch 135/350\n",
      "574/574 [==============================] - 0s 400us/step - loss: 1.4287 - acc: 0.6167\n",
      "Epoch 136/350\n",
      "574/574 [==============================] - 0s 399us/step - loss: 1.4235 - acc: 0.6376 0s - loss: 1.3744 - acc: 0.6\n",
      "Epoch 137/350\n",
      "574/574 [==============================] - 0s 404us/step - loss: 1.4074 - acc: 0.6376\n",
      "Epoch 138/350\n",
      "574/574 [==============================] - 0s 401us/step - loss: 1.3973 - acc: 0.6446\n",
      "Epoch 139/350\n",
      "574/574 [==============================] - 0s 423us/step - loss: 1.3892 - acc: 0.6446\n",
      "Epoch 140/350\n",
      "574/574 [==============================] - 0s 547us/step - loss: 1.3799 - acc: 0.6446\n",
      "Epoch 141/350\n",
      "574/574 [==============================] - 0s 633us/step - loss: 1.3708 - acc: 0.6551\n",
      "Epoch 142/350\n",
      "574/574 [==============================] - 0s 627us/step - loss: 1.3677 - acc: 0.6411\n",
      "Epoch 143/350\n",
      "574/574 [==============================] - 0s 511us/step - loss: 1.3569 - acc: 0.6551\n",
      "Epoch 144/350\n",
      "574/574 [==============================] - 0s 453us/step - loss: 1.3456 - acc: 0.6568\n",
      "Epoch 145/350\n",
      "574/574 [==============================] - 0s 491us/step - loss: 1.3394 - acc: 0.6498\n",
      "Epoch 146/350\n",
      "574/574 [==============================] - 0s 454us/step - loss: 1.3291 - acc: 0.6638\n",
      "Epoch 147/350\n",
      "574/574 [==============================] - 0s 467us/step - loss: 1.3268 - acc: 0.6655\n",
      "Epoch 148/350\n",
      "574/574 [==============================] - 0s 486us/step - loss: 1.3156 - acc: 0.6603\n",
      "Epoch 149/350\n",
      "574/574 [==============================] - 0s 416us/step - loss: 1.3088 - acc: 0.6620\n",
      "Epoch 150/350\n",
      "574/574 [==============================] - 0s 420us/step - loss: 1.3026 - acc: 0.6760\n",
      "Epoch 151/350\n",
      "574/574 [==============================] - 0s 411us/step - loss: 1.2910 - acc: 0.6638\n",
      "Epoch 152/350\n",
      "574/574 [==============================] - 0s 488us/step - loss: 1.2881 - acc: 0.6620 0s - loss: 1.1519 - acc: 0.\n",
      "Epoch 153/350\n",
      "574/574 [==============================] - 0s 568us/step - loss: 1.2792 - acc: 0.6672\n",
      "Epoch 154/350\n",
      "574/574 [==============================] - 0s 429us/step - loss: 1.2724 - acc: 0.6794\n",
      "Epoch 155/350\n",
      "574/574 [==============================] - 0s 368us/step - loss: 1.2701 - acc: 0.6777\n",
      "Epoch 156/350\n",
      "574/574 [==============================] - 0s 392us/step - loss: 1.2569 - acc: 0.6725\n",
      "Epoch 157/350\n",
      "574/574 [==============================] - 0s 379us/step - loss: 1.2517 - acc: 0.6760\n",
      "Epoch 158/350\n",
      "574/574 [==============================] - 0s 358us/step - loss: 1.2451 - acc: 0.6899\n",
      "Epoch 159/350\n",
      "574/574 [==============================] - 0s 365us/step - loss: 1.2395 - acc: 0.6864\n",
      "Epoch 160/350\n",
      "574/574 [==============================] - 0s 314us/step - loss: 1.2358 - acc: 0.6899\n",
      "Epoch 161/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 0s 318us/step - loss: 1.2230 - acc: 0.6777\n",
      "Epoch 162/350\n",
      "574/574 [==============================] - 0s 309us/step - loss: 1.2189 - acc: 0.6794\n",
      "Epoch 163/350\n",
      "574/574 [==============================] - 0s 372us/step - loss: 1.2140 - acc: 0.6899\n",
      "Epoch 164/350\n",
      "574/574 [==============================] - 0s 299us/step - loss: 1.2120 - acc: 0.6812\n",
      "Epoch 165/350\n",
      "574/574 [==============================] - 0s 306us/step - loss: 1.2021 - acc: 0.6882\n",
      "Epoch 166/350\n",
      "574/574 [==============================] - 0s 297us/step - loss: 1.1999 - acc: 0.6916\n",
      "Epoch 167/350\n",
      "574/574 [==============================] - 0s 321us/step - loss: 1.1958 - acc: 0.6899\n",
      "Epoch 168/350\n",
      "574/574 [==============================] - 0s 300us/step - loss: 1.1876 - acc: 0.6864\n",
      "Epoch 169/350\n",
      "574/574 [==============================] - 0s 314us/step - loss: 1.1826 - acc: 0.6934\n",
      "Epoch 170/350\n",
      "574/574 [==============================] - 0s 303us/step - loss: 1.1831 - acc: 0.6899\n",
      "Epoch 171/350\n",
      "574/574 [==============================] - 0s 305us/step - loss: 1.1721 - acc: 0.6951\n",
      "Epoch 172/350\n",
      "574/574 [==============================] - 0s 296us/step - loss: 1.1669 - acc: 0.6899\n",
      "Epoch 173/350\n",
      "574/574 [==============================] - 0s 307us/step - loss: 1.1653 - acc: 0.6899\n",
      "Epoch 174/350\n",
      "574/574 [==============================] - ETA: 0s - loss: 1.1564 - acc: 0.697 - 0s 318us/step - loss: 1.1596 - acc: 0.6899\n",
      "Epoch 175/350\n",
      "574/574 [==============================] - 0s 302us/step - loss: 1.1565 - acc: 0.6951\n",
      "Epoch 176/350\n",
      "574/574 [==============================] - 0s 306us/step - loss: 1.1479 - acc: 0.6934\n",
      "Epoch 177/350\n",
      "574/574 [==============================] - 0s 307us/step - loss: 1.1400 - acc: 0.6934 0s - loss: 1.1034 - acc: 0.706\n",
      "Epoch 178/350\n",
      "574/574 [==============================] - 0s 298us/step - loss: 1.1386 - acc: 0.7021\n",
      "Epoch 179/350\n",
      "574/574 [==============================] - 0s 316us/step - loss: 1.1336 - acc: 0.6934\n",
      "Epoch 180/350\n",
      "574/574 [==============================] - 0s 308us/step - loss: 1.1276 - acc: 0.6986\n",
      "Epoch 181/350\n",
      "574/574 [==============================] - 0s 303us/step - loss: 1.1265 - acc: 0.7056\n",
      "Epoch 182/350\n",
      "574/574 [==============================] - 0s 314us/step - loss: 1.1209 - acc: 0.7003\n",
      "Epoch 183/350\n",
      "574/574 [==============================] - 0s 314us/step - loss: 1.1160 - acc: 0.7073\n",
      "Epoch 184/350\n",
      "574/574 [==============================] - 0s 317us/step - loss: 1.1145 - acc: 0.6986\n",
      "Epoch 185/350\n",
      "574/574 [==============================] - 0s 308us/step - loss: 1.1145 - acc: 0.6951\n",
      "Epoch 186/350\n",
      "574/574 [==============================] - 0s 302us/step - loss: 1.1097 - acc: 0.7056\n",
      "Epoch 187/350\n",
      "574/574 [==============================] - 0s 361us/step - loss: 1.1030 - acc: 0.7003\n",
      "Epoch 188/350\n",
      "574/574 [==============================] - 0s 382us/step - loss: 1.1001 - acc: 0.6986\n",
      "Epoch 189/350\n",
      "574/574 [==============================] - 0s 388us/step - loss: 1.0933 - acc: 0.6969\n",
      "Epoch 190/350\n",
      "574/574 [==============================] - 0s 372us/step - loss: 1.0890 - acc: 0.6986\n",
      "Epoch 191/350\n",
      "574/574 [==============================] - 0s 375us/step - loss: 1.0881 - acc: 0.7056\n",
      "Epoch 192/350\n",
      "574/574 [==============================] - 0s 371us/step - loss: 1.0821 - acc: 0.7125\n",
      "Epoch 193/350\n",
      "574/574 [==============================] - 0s 358us/step - loss: 1.0791 - acc: 0.7091\n",
      "Epoch 194/350\n",
      "574/574 [==============================] - 0s 600us/step - loss: 1.0733 - acc: 0.7073\n",
      "Epoch 195/350\n",
      "574/574 [==============================] - 0s 511us/step - loss: 1.0753 - acc: 0.7073\n",
      "Epoch 196/350\n",
      "574/574 [==============================] - 0s 455us/step - loss: 1.0695 - acc: 0.7178\n",
      "Epoch 197/350\n",
      "574/574 [==============================] - 0s 438us/step - loss: 1.0748 - acc: 0.7021\n",
      "Epoch 198/350\n",
      "574/574 [==============================] - 0s 466us/step - loss: 1.0637 - acc: 0.7038\n",
      "Epoch 199/350\n",
      "574/574 [==============================] - 0s 407us/step - loss: 1.0533 - acc: 0.7091\n",
      "Epoch 200/350\n",
      "574/574 [==============================] - 0s 384us/step - loss: 1.0542 - acc: 0.7125\n",
      "Epoch 201/350\n",
      "574/574 [==============================] - 0s 386us/step - loss: 1.0495 - acc: 0.7038\n",
      "Epoch 202/350\n",
      "574/574 [==============================] - 0s 369us/step - loss: 1.0507 - acc: 0.7021\n",
      "Epoch 203/350\n",
      "574/574 [==============================] - 0s 345us/step - loss: 1.0439 - acc: 0.7091\n",
      "Epoch 204/350\n",
      "574/574 [==============================] - 0s 368us/step - loss: 1.0379 - acc: 0.7091\n",
      "Epoch 205/350\n",
      "574/574 [==============================] - 0s 407us/step - loss: 1.0389 - acc: 0.6986\n",
      "Epoch 206/350\n",
      "574/574 [==============================] - 0s 487us/step - loss: 1.0372 - acc: 0.7056\n",
      "Epoch 207/350\n",
      "574/574 [==============================] - 0s 458us/step - loss: 1.0332 - acc: 0.7091\n",
      "Epoch 208/350\n",
      "574/574 [==============================] - 0s 489us/step - loss: 1.0261 - acc: 0.7108\n",
      "Epoch 209/350\n",
      "574/574 [==============================] - 0s 454us/step - loss: 1.0293 - acc: 0.7091\n",
      "Epoch 210/350\n",
      "574/574 [==============================] - 0s 428us/step - loss: 1.0285 - acc: 0.7038\n",
      "Epoch 211/350\n",
      "574/574 [==============================] - 0s 409us/step - loss: 1.0212 - acc: 0.7108\n",
      "Epoch 212/350\n",
      "574/574 [==============================] - 0s 385us/step - loss: 1.0204 - acc: 0.7056\n",
      "Epoch 213/350\n",
      "574/574 [==============================] - 0s 441us/step - loss: 1.0187 - acc: 0.7125\n",
      "Epoch 214/350\n",
      "574/574 [==============================] - 0s 414us/step - loss: 1.0100 - acc: 0.7125 0s - loss: 0.9488 - acc: 0.7\n",
      "Epoch 215/350\n",
      "574/574 [==============================] - 0s 416us/step - loss: 1.0115 - acc: 0.6986\n",
      "Epoch 216/350\n",
      "574/574 [==============================] - 0s 392us/step - loss: 1.0132 - acc: 0.7160\n",
      "Epoch 217/350\n",
      "574/574 [==============================] - 0s 370us/step - loss: 1.0044 - acc: 0.7091\n",
      "Epoch 218/350\n",
      "574/574 [==============================] - 0s 424us/step - loss: 1.0011 - acc: 0.7247\n",
      "Epoch 219/350\n",
      "574/574 [==============================] - 0s 415us/step - loss: 0.9998 - acc: 0.7178\n",
      "Epoch 220/350\n",
      "574/574 [==============================] - 0s 412us/step - loss: 0.9967 - acc: 0.7160\n",
      "Epoch 221/350\n",
      "574/574 [==============================] - 0s 415us/step - loss: 0.9933 - acc: 0.7178\n",
      "Epoch 222/350\n",
      "574/574 [==============================] - 0s 590us/step - loss: 0.9904 - acc: 0.7195 0s - loss: 0.9037 - acc: 0.\n",
      "Epoch 223/350\n",
      "574/574 [==============================] - 0s 471us/step - loss: 0.9907 - acc: 0.7195\n",
      "Epoch 224/350\n",
      "574/574 [==============================] - 0s 483us/step - loss: 0.9925 - acc: 0.7213\n",
      "Epoch 225/350\n",
      "574/574 [==============================] - 0s 511us/step - loss: 0.9882 - acc: 0.7178\n",
      "Epoch 226/350\n",
      "574/574 [==============================] - ETA: 0s - loss: 0.9658 - acc: 0.718 - 0s 477us/step - loss: 0.9803 - acc: 0.7160\n",
      "Epoch 227/350\n",
      "574/574 [==============================] - 0s 768us/step - loss: 0.9834 - acc: 0.7195\n",
      "Epoch 228/350\n",
      "574/574 [==============================] - 0s 499us/step - loss: 0.9801 - acc: 0.7143\n",
      "Epoch 229/350\n",
      "574/574 [==============================] - 0s 535us/step - loss: 0.9769 - acc: 0.7195\n",
      "Epoch 230/350\n",
      "574/574 [==============================] - 0s 459us/step - loss: 0.9744 - acc: 0.7108\n",
      "Epoch 231/350\n",
      "574/574 [==============================] - 0s 387us/step - loss: 0.9740 - acc: 0.7125\n",
      "Epoch 232/350\n",
      "574/574 [==============================] - 0s 369us/step - loss: 0.9688 - acc: 0.7195\n",
      "Epoch 233/350\n",
      "574/574 [==============================] - 0s 378us/step - loss: 0.9675 - acc: 0.7178\n",
      "Epoch 234/350\n",
      "574/574 [==============================] - 0s 387us/step - loss: 0.9681 - acc: 0.7160\n",
      "Epoch 235/350\n",
      "574/574 [==============================] - 0s 392us/step - loss: 0.9668 - acc: 0.7178\n",
      "Epoch 236/350\n",
      "574/574 [==============================] - 0s 491us/step - loss: 0.9689 - acc: 0.7160\n",
      "Epoch 237/350\n",
      "574/574 [==============================] - 0s 410us/step - loss: 0.9666 - acc: 0.7178\n",
      "Epoch 238/350\n",
      "574/574 [==============================] - 0s 518us/step - loss: 0.9646 - acc: 0.7160\n",
      "Epoch 239/350\n",
      "574/574 [==============================] - 0s 420us/step - loss: 0.9547 - acc: 0.7195\n",
      "Epoch 240/350\n",
      "574/574 [==============================] - 0s 423us/step - loss: 0.9574 - acc: 0.7195\n",
      "Epoch 241/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 0s 418us/step - loss: 0.9561 - acc: 0.7056\n",
      "Epoch 242/350\n",
      "574/574 [==============================] - 0s 386us/step - loss: 0.9530 - acc: 0.7195\n",
      "Epoch 243/350\n",
      "574/574 [==============================] - 0s 373us/step - loss: 0.9496 - acc: 0.7195\n",
      "Epoch 244/350\n",
      "574/574 [==============================] - 0s 379us/step - loss: 0.9497 - acc: 0.7143\n",
      "Epoch 245/350\n",
      "574/574 [==============================] - 0s 384us/step - loss: 0.9459 - acc: 0.7178\n",
      "Epoch 246/350\n",
      "574/574 [==============================] - 0s 406us/step - loss: 0.9432 - acc: 0.7247\n",
      "Epoch 247/350\n",
      "574/574 [==============================] - 0s 362us/step - loss: 0.9405 - acc: 0.7213\n",
      "Epoch 248/350\n",
      "574/574 [==============================] - 0s 395us/step - loss: 0.9420 - acc: 0.7195\n",
      "Epoch 249/350\n",
      "574/574 [==============================] - 0s 460us/step - loss: 0.9398 - acc: 0.7195\n",
      "Epoch 250/350\n",
      "574/574 [==============================] - 0s 336us/step - loss: 0.9369 - acc: 0.7265\n",
      "Epoch 251/350\n",
      "574/574 [==============================] - 0s 337us/step - loss: 0.9352 - acc: 0.7230\n",
      "Epoch 252/350\n",
      "574/574 [==============================] - 0s 354us/step - loss: 0.9340 - acc: 0.7091\n",
      "Epoch 253/350\n",
      "574/574 [==============================] - 0s 322us/step - loss: 0.9307 - acc: 0.7213\n",
      "Epoch 254/350\n",
      "574/574 [==============================] - 0s 336us/step - loss: 0.9305 - acc: 0.7195\n",
      "Epoch 255/350\n",
      "574/574 [==============================] - 0s 347us/step - loss: 0.9295 - acc: 0.7300\n",
      "Epoch 256/350\n",
      "574/574 [==============================] - 0s 321us/step - loss: 0.9252 - acc: 0.7282\n",
      "Epoch 257/350\n",
      "574/574 [==============================] - 0s 321us/step - loss: 0.9261 - acc: 0.7230\n",
      "Epoch 258/350\n",
      "574/574 [==============================] - 0s 319us/step - loss: 0.9238 - acc: 0.7247 0s - loss: 0.9171 - acc: 0.7\n",
      "Epoch 259/350\n",
      "574/574 [==============================] - 0s 311us/step - loss: 0.9272 - acc: 0.7230 0s - loss: 0.9178 - acc: 0.71\n",
      "Epoch 260/350\n",
      "574/574 [==============================] - 0s 320us/step - loss: 0.9297 - acc: 0.7213\n",
      "Epoch 261/350\n",
      "574/574 [==============================] - 0s 303us/step - loss: 0.9239 - acc: 0.7282\n",
      "Epoch 262/350\n",
      "574/574 [==============================] - 0s 262us/step - loss: 0.9188 - acc: 0.7247\n",
      "Epoch 263/350\n",
      "574/574 [==============================] - 0s 247us/step - loss: 0.9198 - acc: 0.7265\n",
      "Epoch 264/350\n",
      "574/574 [==============================] - 0s 255us/step - loss: 0.9233 - acc: 0.7195\n",
      "Epoch 265/350\n",
      "574/574 [==============================] - 0s 247us/step - loss: 0.9190 - acc: 0.7247\n",
      "Epoch 266/350\n",
      "574/574 [==============================] - 0s 248us/step - loss: 0.9151 - acc: 0.7195\n",
      "Epoch 267/350\n",
      "574/574 [==============================] - 0s 248us/step - loss: 0.9134 - acc: 0.7265\n",
      "Epoch 268/350\n",
      "574/574 [==============================] - 0s 248us/step - loss: 0.9136 - acc: 0.7178\n",
      "Epoch 269/350\n",
      "574/574 [==============================] - 0s 246us/step - loss: 0.9096 - acc: 0.7178\n",
      "Epoch 270/350\n",
      "574/574 [==============================] - 0s 248us/step - loss: 0.9073 - acc: 0.7178\n",
      "Epoch 271/350\n",
      "574/574 [==============================] - 0s 253us/step - loss: 0.9107 - acc: 0.7178\n",
      "Epoch 272/350\n",
      "574/574 [==============================] - 0s 252us/step - loss: 0.9066 - acc: 0.7178\n",
      "Epoch 273/350\n",
      "574/574 [==============================] - 0s 247us/step - loss: 0.9042 - acc: 0.7247\n",
      "Epoch 274/350\n",
      "574/574 [==============================] - 0s 247us/step - loss: 0.9016 - acc: 0.7230\n",
      "Epoch 275/350\n",
      "574/574 [==============================] - 0s 248us/step - loss: 0.9045 - acc: 0.7125\n",
      "Epoch 276/350\n",
      "574/574 [==============================] - 0s 247us/step - loss: 0.9035 - acc: 0.7265\n",
      "Epoch 277/350\n",
      "574/574 [==============================] - 0s 246us/step - loss: 0.9014 - acc: 0.7213\n",
      "Epoch 278/350\n",
      "574/574 [==============================] - 0s 249us/step - loss: 0.9004 - acc: 0.7282\n",
      "Epoch 279/350\n",
      "574/574 [==============================] - 0s 247us/step - loss: 0.8992 - acc: 0.7213\n",
      "Epoch 280/350\n",
      "574/574 [==============================] - 0s 261us/step - loss: 0.8986 - acc: 0.7247\n",
      "Epoch 281/350\n",
      "574/574 [==============================] - 0s 361us/step - loss: 0.8945 - acc: 0.7282\n",
      "Epoch 282/350\n",
      "574/574 [==============================] - 0s 329us/step - loss: 0.8986 - acc: 0.7247\n",
      "Epoch 283/350\n",
      "574/574 [==============================] - 0s 304us/step - loss: 0.8980 - acc: 0.7195\n",
      "Epoch 284/350\n",
      "574/574 [==============================] - 0s 318us/step - loss: 0.8928 - acc: 0.7230\n",
      "Epoch 285/350\n",
      "574/574 [==============================] - 0s 303us/step - loss: 0.8947 - acc: 0.7282\n",
      "Epoch 286/350\n",
      "574/574 [==============================] - ETA: 0s - loss: 0.8698 - acc: 0.734 - 0s 313us/step - loss: 0.8914 - acc: 0.7247\n",
      "Epoch 287/350\n",
      "574/574 [==============================] - 0s 352us/step - loss: 0.8906 - acc: 0.7178\n",
      "Epoch 288/350\n",
      "574/574 [==============================] - 0s 300us/step - loss: 0.8891 - acc: 0.7178\n",
      "Epoch 289/350\n",
      "574/574 [==============================] - 0s 311us/step - loss: 0.8928 - acc: 0.7178\n",
      "Epoch 290/350\n",
      "574/574 [==============================] - 0s 275us/step - loss: 0.8869 - acc: 0.7265\n",
      "Epoch 291/350\n",
      "574/574 [==============================] - 0s 275us/step - loss: 0.8885 - acc: 0.7143\n",
      "Epoch 292/350\n",
      "574/574 [==============================] - 0s 263us/step - loss: 0.8908 - acc: 0.7265\n",
      "Epoch 293/350\n",
      "574/574 [==============================] - 0s 270us/step - loss: 0.8837 - acc: 0.7230\n",
      "Epoch 294/350\n",
      "574/574 [==============================] - 0s 252us/step - loss: 0.8823 - acc: 0.7282\n",
      "Epoch 295/350\n",
      "574/574 [==============================] - 0s 255us/step - loss: 0.8834 - acc: 0.7247\n",
      "Epoch 296/350\n",
      "574/574 [==============================] - 0s 259us/step - loss: 0.8827 - acc: 0.7178\n",
      "Epoch 297/350\n",
      "574/574 [==============================] - 0s 256us/step - loss: 0.8794 - acc: 0.7247\n",
      "Epoch 298/350\n",
      "574/574 [==============================] - 0s 262us/step - loss: 0.8794 - acc: 0.7247\n",
      "Epoch 299/350\n",
      "574/574 [==============================] - 0s 266us/step - loss: 0.8800 - acc: 0.7195\n",
      "Epoch 300/350\n",
      "574/574 [==============================] - 0s 260us/step - loss: 0.8813 - acc: 0.7213\n",
      "Epoch 301/350\n",
      "574/574 [==============================] - 0s 251us/step - loss: 0.8788 - acc: 0.7213\n",
      "Epoch 302/350\n",
      "574/574 [==============================] - 0s 253us/step - loss: 0.8776 - acc: 0.7265\n",
      "Epoch 303/350\n",
      "574/574 [==============================] - 0s 261us/step - loss: 0.8768 - acc: 0.7300 0s - loss: 0.8819 - acc: 0.733\n",
      "Epoch 304/350\n",
      "574/574 [==============================] - 0s 292us/step - loss: 0.8753 - acc: 0.7300\n",
      "Epoch 305/350\n",
      "574/574 [==============================] - 0s 322us/step - loss: 0.8797 - acc: 0.7247\n",
      "Epoch 306/350\n",
      "574/574 [==============================] - 0s 351us/step - loss: 0.8738 - acc: 0.7317\n",
      "Epoch 307/350\n",
      "574/574 [==============================] - 0s 355us/step - loss: 0.8740 - acc: 0.7195\n",
      "Epoch 308/350\n",
      "574/574 [==============================] - 0s 354us/step - loss: 0.8712 - acc: 0.7160\n",
      "Epoch 309/350\n",
      "574/574 [==============================] - 0s 327us/step - loss: 0.8751 - acc: 0.7213\n",
      "Epoch 310/350\n",
      "574/574 [==============================] - 0s 332us/step - loss: 0.8737 - acc: 0.7230\n",
      "Epoch 311/350\n",
      "574/574 [==============================] - 0s 293us/step - loss: 0.8746 - acc: 0.7178\n",
      "Epoch 312/350\n",
      "574/574 [==============================] - 0s 291us/step - loss: 0.8717 - acc: 0.7247\n",
      "Epoch 313/350\n",
      "574/574 [==============================] - 0s 288us/step - loss: 0.8706 - acc: 0.7125\n",
      "Epoch 314/350\n",
      "574/574 [==============================] - 0s 257us/step - loss: 0.8680 - acc: 0.7178\n",
      "Epoch 315/350\n",
      "574/574 [==============================] - 0s 331us/step - loss: 0.8715 - acc: 0.7213\n",
      "Epoch 316/350\n",
      "574/574 [==============================] - 0s 521us/step - loss: 0.8700 - acc: 0.7247 0s - loss: 0.8714 - acc: 0.72\n",
      "Epoch 317/350\n",
      "574/574 [==============================] - 0s 540us/step - loss: 0.8662 - acc: 0.7195\n",
      "Epoch 318/350\n",
      "574/574 [==============================] - 0s 703us/step - loss: 0.8640 - acc: 0.7143 0s - loss: 0.8984 - acc: 0.7\n",
      "Epoch 319/350\n",
      "574/574 [==============================] - 0s 428us/step - loss: 0.8669 - acc: 0.7160\n",
      "Epoch 320/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 0s 474us/step - loss: 0.8674 - acc: 0.7230 0s - loss: 0.8701 - acc: 0.7\n",
      "Epoch 321/350\n",
      "574/574 [==============================] - 0s 515us/step - loss: 0.8674 - acc: 0.7213\n",
      "Epoch 322/350\n",
      "574/574 [==============================] - 0s 549us/step - loss: 0.8608 - acc: 0.7265\n",
      "Epoch 323/350\n",
      "574/574 [==============================] - 0s 460us/step - loss: 0.8622 - acc: 0.7195\n",
      "Epoch 324/350\n",
      "574/574 [==============================] - 0s 295us/step - loss: 0.8648 - acc: 0.7213\n",
      "Epoch 325/350\n",
      "574/574 [==============================] - 0s 288us/step - loss: 0.8637 - acc: 0.7160\n",
      "Epoch 326/350\n",
      "574/574 [==============================] - 0s 329us/step - loss: 0.8627 - acc: 0.7247\n",
      "Epoch 327/350\n",
      "574/574 [==============================] - 0s 309us/step - loss: 0.8643 - acc: 0.7247\n",
      "Epoch 328/350\n",
      "574/574 [==============================] - 0s 297us/step - loss: 0.8588 - acc: 0.7230\n",
      "Epoch 329/350\n",
      "574/574 [==============================] - 0s 305us/step - loss: 0.8608 - acc: 0.7160\n",
      "Epoch 330/350\n",
      "574/574 [==============================] - 0s 299us/step - loss: 0.8616 - acc: 0.7230\n",
      "Epoch 331/350\n",
      "574/574 [==============================] - 0s 288us/step - loss: 0.8587 - acc: 0.7195\n",
      "Epoch 332/350\n",
      "574/574 [==============================] - 0s 288us/step - loss: 0.8562 - acc: 0.7213\n",
      "Epoch 333/350\n",
      "574/574 [==============================] - 0s 311us/step - loss: 0.8579 - acc: 0.7230\n",
      "Epoch 334/350\n",
      "574/574 [==============================] - 0s 325us/step - loss: 0.8567 - acc: 0.7213\n",
      "Epoch 335/350\n",
      "574/574 [==============================] - 0s 311us/step - loss: 0.8545 - acc: 0.7230\n",
      "Epoch 336/350\n",
      "574/574 [==============================] - 0s 302us/step - loss: 0.8571 - acc: 0.7125 0s - loss: 0.8705 - acc: 0.71\n",
      "Epoch 337/350\n",
      "574/574 [==============================] - 0s 367us/step - loss: 0.8603 - acc: 0.7195\n",
      "Epoch 338/350\n",
      "574/574 [==============================] - 0s 423us/step - loss: 0.8539 - acc: 0.7230\n",
      "Epoch 339/350\n",
      "574/574 [==============================] - 0s 321us/step - loss: 0.8564 - acc: 0.7195\n",
      "Epoch 340/350\n",
      "574/574 [==============================] - 0s 321us/step - loss: 0.8532 - acc: 0.7230\n",
      "Epoch 341/350\n",
      "574/574 [==============================] - 0s 314us/step - loss: 0.8507 - acc: 0.7213\n",
      "Epoch 342/350\n",
      "574/574 [==============================] - 0s 520us/step - loss: 0.8522 - acc: 0.7247\n",
      "Epoch 343/350\n",
      "574/574 [==============================] - 0s 384us/step - loss: 0.8506 - acc: 0.7213\n",
      "Epoch 344/350\n",
      "574/574 [==============================] - 0s 398us/step - loss: 0.8535 - acc: 0.7213\n",
      "Epoch 345/350\n",
      "574/574 [==============================] - 0s 480us/step - loss: 0.8485 - acc: 0.7195\n",
      "Epoch 346/350\n",
      "574/574 [==============================] - 0s 399us/step - loss: 0.8482 - acc: 0.7195\n",
      "Epoch 347/350\n",
      "574/574 [==============================] - 0s 391us/step - loss: 0.8499 - acc: 0.7143\n",
      "Epoch 348/350\n",
      "574/574 [==============================] - 0s 346us/step - loss: 0.8494 - acc: 0.7213\n",
      "Epoch 349/350\n",
      "574/574 [==============================] - 0s 401us/step - loss: 0.8541 - acc: 0.7195\n",
      "Epoch 350/350\n",
      "574/574 [==============================] - 0s 434us/step - loss: 0.8475 - acc: 0.7213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a72af87390>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=350,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardando el modelo ya entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_5.h5')\n",
    "dump(tokenizer,open('tokenizer_5.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando texto Neural Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_5.h5')\n",
    "tokenizer = load(open('tokenizer_5.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FunciÃ³n recursiva que genera texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text,next_words,max_sequence_len, model):\n",
    "  for j in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "      if index == predicted:\n",
    "        output_word = word\n",
    "        break\n",
    "    seed_text += \" \" + output_word\n",
    "  return seed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john buy icecream car future not buy house sell yesterday\n"
     ]
    }
   ],
   "source": [
    "text=generate_text(\"john buy icecream\",7,max_sequence_len,model)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
