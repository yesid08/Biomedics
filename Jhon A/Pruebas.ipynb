{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0\n",
      "0         John\n",
      "1       writes\n",
      "2          his\n",
      "3     homework\n",
      "4            I\n",
      "5      visited\n",
      "6         John\n",
      "7        there\n",
      "8    yesterday\n",
      "9            I\n",
      "10     visited\n",
      "11        John\n",
      "12       there\n",
      "13   yesterday\n",
      "14        Mary\n",
      "15       loves\n",
      "16        John\n",
      "17        Mary\n",
      "18       loves\n",
      "19        John\n",
      "20        Sure\n",
      "21        John\n",
      "22         can\n",
      "23          go\n",
      "24       there\n",
      "25        Sure\n",
      "26        John\n",
      "27         can\n",
      "28          go\n",
      "29       there\n",
      "..         ...\n",
      "848       girl\n",
      "849        the\n",
      "850        box\n",
      "851       John\n",
      "852     really\n",
      "853        can\n",
      "854        get\n",
      "855         it\n",
      "856       John\n",
      "857    doesn't\n",
      "858      visit\n",
      "859       Mary\n",
      "860         he\n",
      "861     visits\n",
      "862        his\n",
      "863     mother\n",
      "864         He\n",
      "865       puts\n",
      "866        the\n",
      "867       book\n",
      "868      aside\n",
      "869       John\n",
      "870    doesn't\n",
      "871     arrive\n",
      "872        Who\n",
      "873      likes\n",
      "874  chocolate\n",
      "875        Who\n",
      "876     visits\n",
      "877       John\n",
      "\n",
      "[878 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "filename=\"train.sentences.pronunciations.multi.translations.csv\"\n",
    "elements=pd.read_csv(filename, delimiter=\";\", error_bad_lines=False)\n",
    "words=elements['orth']\n",
    "translations=elements['translation']\n",
    "\n",
    "words_separated=list()\n",
    "for row in words:\n",
    "    words_separated=words_separated+row.split()\n",
    "transl_separated=list()\n",
    "for row in translations:\n",
    "    transl_separated=transl_separated+row.split()\n",
    "    \n",
    "    # elimina los puntos finales \n",
    "words=list()\n",
    "for word in transl_separated:\n",
    "    word=str(word).rstrip(\".\")\n",
    "    word=str(word).rstrip(\"?\")\n",
    "    word=str(word).rstrip(\",\")\n",
    "    word=str(word).rstrip(\";\")\n",
    "    words.append(word)\n",
    "    \n",
    "# convierte las listas en dataframes\n",
    "words_separated=pd.DataFrame(words_separated)\n",
    "transl_separated=pd.DataFrame(words)\n",
    "print(transl_separated)\n",
    "\n",
    "# todas las palabras las convierte a min√∫sculas\n",
    "words_separated=words_separated.applymap(str.lower)\n",
    "transl_separated=transl_separated.applymap(str.lower)\n",
    "\n",
    "# saca las frecuencias de cada palabra, primero convirtiendo en np.array\n",
    "transl_separated=np.array(transl_separated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "\n",
    "def build_dataset(words):\n",
    "  count = [['UNK', -1]]\n",
    "  count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "  dictionary = dict()\n",
    "  for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "  data = list()\n",
    "  unk_count = 0\n",
    "  for word in words:\n",
    "    if word in dictionary:\n",
    "      index = dictionary[word]\n",
    "    else:\n",
    "      index = 0  # dictionary['UNK']\n",
    "      unk_count = unk_count + 1\n",
    "    data.append(index)\n",
    "  count[0][1] = unk_count\n",
    "  reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "  return data, count, dictionary, reverse_dictionary\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(transl_separated)\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10])\n",
    "del words  # Hint to reduce memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
