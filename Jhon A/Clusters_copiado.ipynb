{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CDicSigns.jef', 'CDicSigns_labels.jef', 'CDicSigns_words.jef']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../codebookss\"\n",
    "conectivity_path = \"{}/{}\".format(path,\"diccionario_1_connectivity\")\n",
    "distance_path = \"{}/{}\".format(path,\"diccionario_1_distance\")\n",
    "spectral_path = \"{}/{}\".format(path,\"diccionario_3_spectral\")\n",
    "conectivity_signs = \"{}/{}\".format(conectivity_path,\"CDicSigns.jef\")\n",
    "conectivity_labels = \"{}/{}\".format(conectivity_path,\"CDicSigns_labels.jef\")\n",
    "conectivity_words = \"{}/{}\".format(conectivity_path,\"CDicSigns_words.jef\")\n",
    "conectivity_signs_np = np.loadtxt(conectivity_signs)\n",
    "conectivity_labels_np = np.loadtxt(conectivity_labels)\n",
    "conectivity_words_np = np.loadtxt(conectivity_words)\n",
    "os.listdir(distance_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_shape = conectivity_labels_np.shape\n",
    "words_shape = conectivity_words_np.shape\n",
    "signs_shape = conectivity_signs_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word is [0.15855973 0.13279379 0.12510098 0.0051269  0.04210306 0.18600278\n",
      " 0.27352444 0.07678834]  and the label for the word is 78.0\n"
     ]
    }
   ],
   "source": [
    "print (\"the word is {}  and the label for the word is {}\".format(conectivity_words_np[0],conectivity_labels_np[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(columns=[\"Word\" , \"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = words_shape[0]\n",
    "for i in range (rows):\n",
    "    table.at[i,\"Word\"] = conectivity_words_np[i,:]\n",
    "    table.at[i,\"index\"] = conectivity_labels_np[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_frec = table.groupby('index').count()\n",
    "table[\"Frecuency\"]  = table.groupby('index')['index'].transform('count')\n",
    "\n",
    "# table_frec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=table.sort_values('Frecuency')\n",
    "# table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(trainFileName):\n",
    "    train_data = pd.read_csv(trainFileName,delimiter=\";\")\n",
    "    sentences_train = [sentence[:len(sentence) -1 ] for sentence in train_data.orth]\n",
    "    sentences = sentences_train\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.split()\n",
    "        for  i in range (len(sentence)):\n",
    "            word = sentence[i]\n",
    "            word = str.lower(word)\n",
    "            word = word.rstrip(\",\")\n",
    "            word = word.rstrip(\".\")\n",
    "            word = word.rstrip(\"?\")\n",
    "            words.append(word)\n",
    "    del train_data\n",
    "    del sentences\n",
    "    del sentences_train\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFileName = 'train.sentences.pronunciations.multi.translations.csv'\n",
    "words = create_dataset(trainFileName)\n",
    "len(words)\n",
    "\n",
    "\n",
    "frecuences=collections.Counter(words).most_common()\n",
    "frecuences=pd.DataFrame(frecuences)\n",
    "frecuences.columns = ['Words', 'Frecuences']\n",
    "frecuences=frecuences.sort_values('Frecuences')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((114, 2), (710, 3))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frecuences.shape, table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Words', 'Frecuences'], dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2=table[0:114]\n",
    "table_2.shape\n",
    "frecuences.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-656fe3682121>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfrecuences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'concat'"
     ]
    }
   ],
   "source": [
    "frecuences.concat(table_2,axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
